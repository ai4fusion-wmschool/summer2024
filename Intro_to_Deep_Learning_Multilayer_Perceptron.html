
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>An Introduction to the Multilayer Perceptron &#8212; AI for Fusion Energy Summer School (2024)</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=62ba249389abaaa9ffc34bf36a076bdc1d65ee18" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=f31d14ad54b65d19161ba51d4ffff3a77ae00456"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="shortcut icon" href="_static/wm_vertical_single_line_full_color.png"/>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="A very basic example from the NFlows Library" href="NFlows_BasicExample_new.html" />
    <link rel="prev" title="Supervised Learning - Decision Trees, Random Forest and eXtreme Gradient Boosting (XGBoost)" href="Supervised_Learning_DTrees_Random_Forest_and_XGBoost.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="_static/wm_vertical_single_line_full_color.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">AI for Fusion Energy Summer School (2024)</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    AI/ML for Fusion Summer School 2024
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Information on the Summer School
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="schedule.html">
   Schedule
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="lecturers.html">
   Lecturers
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Lecture Notes (to integrate with notebooks below)
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference external" href="https://fabulous-torte-3ed97c.netlify.app/1">
   (6/3/2024) - Intro to Data Science (get started, variance/bias)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://docs.google.com/presentation/d/1-YWO5Q6EkFpkGgiFm0rUaqfGTHaj-Y7OvPYwjettU6A/edit?usp=sharing">
   (6/11/2024) - Intro to Normalizing Flows
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://ai4fusion-wmschool.github.io/summer2024/intro.html">
   test lecture (to appear)
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Notebooks
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="Supervised_Learning_Linear_Regression.html">
   (6/3/2024) Supervised Learning, Linear Regression
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Nonparametric_Methods_GAMs.html">
   (6/5/2024) Nonparametric Methods, GAMs
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Dimensionality_Reduction_Unsupervised_Learning.html">
   (6/6/2024) Dimensionality Reduction, Unsupervised Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Supervised_Learning_DTrees_Random_Forest_and_XGBoost.html">
   (6/7/2024) Supervised Learning, Decision Trees, Random_Forest and XGBoost
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   (6/7/2024) Intro to Deep_Learning, Multilayer_Perceptron
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="NFlows_BasicExample_new.html">
   (6/11/2024) Normalizing Flows - Basic Example
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="NormalizingFlows_GlueX_BCAL_new.html">
   (6/11/2024) Normalizing Flows - GlueX BCAL Example
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Design_BO.html">
   (6/13/2024) Single-Objective Bayesian Optimization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Design_MOBO.html">
   (6/13/2024) Multi-Objective Bayesian Optimization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Design_MOEA.html">
   (6/13/2024) Multi-Objective Genetic Algorithm
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Datasets
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference external" href="https://www.kaggle.com/code/jayrdixit/nuclear-fusion">
   Nuclear Fusion Data (Classification)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://zindi.africa/competitions/multi-machine-disruption-prediction-challenge">
   Multi-Machine Disruption Prediction Challenge for Fusion Energy by ITU (Classification)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://iopscience.iop.org/article/10.1088/1741-4326/abdb91">
   The updated ITPA global H-mode confinement database; description and analysis (Regression)
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Additional resources
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="referencesmd.html">
   References
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/ai4fusion-wmschool/summer2024/main?urlpath=lab/tree/notebooks/Intro_to_Deep_Learning_Multilayer_Perceptron.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
      <li>
        <a href="https://jupyterhub.wm.edu/hub/user-redirect/git-pull?repo=https://github.com/ai4fusion-wmschool/summer2024&urlpath=lab/tree/summer2024/notebooks/Intro_to_Deep_Learning_Multilayer_Perceptron.ipynb&branch=main"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on JupyterHub"
>
  

<span class="headerbtn__icon-container">
  
    <img src="_static/images/logo_jupyterhub.svg">
  </span>
<span class="headerbtn__text-container">JupyterHub</span>
</a>

      </li>
      
      <li>
        <a href="https://colab.research.google.com/github/ai4fusion-wmschool/summer2024/blob/main/notebooks/Intro_to_Deep_Learning_Multilayer_Perceptron.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Colab"
>
  

<span class="headerbtn__icon-container">
  
    <img src="_static/images/logo_colab.png">
  </span>
<span class="headerbtn__text-container">Colab</span>
</a>

      </li>
      
      <li>
        
<button onclick="initThebeSBT()"
  class="headerbtn headerbtn-launch-thebe"
  data-toggle="tooltip"
data-placement="left"
title="Launch Thebe"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-play"></i>
  </span>
<span class="headerbtn__text-container">Live Code</span>
</button>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/ai4fusion-wmschool/summer2024"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/ai4fusion-wmschool/summer2024/issues/new?title=Issue%20on%20page%20%2FIntro_to_Deep_Learning_Multilayer_Perceptron.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="_sources/Intro_to_Deep_Learning_Multilayer_Perceptron.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#font-color-blue-size-5pt-introduction-font">
   <font color="blue" size="5pt">
    Introduction
   </font>
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#font-color-blue-size-5pt-the-artificial-neuron-font">
   <font color="blue" size="5pt">
    The Artificial Neuron
   </font>
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#font-color-blue-size-5pt-brief-history-of-development-font">
   <font color="blue" size="5pt">
    Brief History of Development
   </font>
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#font-color-blue-size-5pt-activation-functions-font">
   <font color="blue" size="5pt">
    Activation Functions
   </font>
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#font-color-blue-size-5pt-backpropagation-font">
   <font color="blue" size="5pt">
    Backpropagation
   </font>
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#font-color-blue-size-5pt-gradient-descent-methods-for-optimization-font">
   <font color="blue" size="5pt">
    Gradient Descent Methods for Optimization
   </font>
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#font-color-blue-size-5pt-dynamic-learning-rates-font">
   <font color="blue" size="5pt">
    Dynamic Learning Rates
   </font>
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#font-color-blue-size-5pt-momentum-gradient-descent-font">
   <font color="blue" size="5pt">
    Momentum Gradient Descent
   </font>
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#font-color-blue-size-5pt-adagrad-adaptive-gradient-descent-font">
   <font color="blue" size="5pt">
    AdaGrad (Adaptive Gradient Descent)
   </font>
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#font-color-blue-size-5pt-rmsprop-root-mean-square-propagation-font">
   <font color="blue" size="5pt">
    RMSProp (Root Mean Square Propagation)
   </font>
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#font-color-blue-size-5pt-adam-adaptive-momentum-gradient-descent-font">
   <font color="blue" size="5pt">
    ADAM (Adaptive Momentum Gradient Descent)
   </font>
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#font-color-blue-size-5pt-multilayer-perceptron-instructional-videos-font">
   <font color="blue" size="5pt">
    Multilayer Perceptron Instructional Videos
   </font>
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#font-color-blue-size-5pt-test-your-understanding-font">
   <font color="blue" size="5pt">
    Test Your Understanding
   </font>
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#font-color-blue-size-6pt-code-applications-font">
   <font color="blue" size="6pt">
    Code Applications
   </font>
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#references">
     References:
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#setup">
   Setup
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#example-of-a-neural-net-in-pytorch-for-classification">
   Example of a Neural Net in PyTorch for Classification
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#example-of-classification-w-class-imbalance">
   Example of Classification w/ Class Imbalance
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>An Introduction to the Multilayer Perceptron </font></h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#font-color-blue-size-5pt-introduction-font">
   <font color="blue" size="5pt">
    Introduction
   </font>
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#font-color-blue-size-5pt-the-artificial-neuron-font">
   <font color="blue" size="5pt">
    The Artificial Neuron
   </font>
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#font-color-blue-size-5pt-brief-history-of-development-font">
   <font color="blue" size="5pt">
    Brief History of Development
   </font>
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#font-color-blue-size-5pt-activation-functions-font">
   <font color="blue" size="5pt">
    Activation Functions
   </font>
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#font-color-blue-size-5pt-backpropagation-font">
   <font color="blue" size="5pt">
    Backpropagation
   </font>
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#font-color-blue-size-5pt-gradient-descent-methods-for-optimization-font">
   <font color="blue" size="5pt">
    Gradient Descent Methods for Optimization
   </font>
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#font-color-blue-size-5pt-dynamic-learning-rates-font">
   <font color="blue" size="5pt">
    Dynamic Learning Rates
   </font>
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#font-color-blue-size-5pt-momentum-gradient-descent-font">
   <font color="blue" size="5pt">
    Momentum Gradient Descent
   </font>
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#font-color-blue-size-5pt-adagrad-adaptive-gradient-descent-font">
   <font color="blue" size="5pt">
    AdaGrad (Adaptive Gradient Descent)
   </font>
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#font-color-blue-size-5pt-rmsprop-root-mean-square-propagation-font">
   <font color="blue" size="5pt">
    RMSProp (Root Mean Square Propagation)
   </font>
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#font-color-blue-size-5pt-adam-adaptive-momentum-gradient-descent-font">
   <font color="blue" size="5pt">
    ADAM (Adaptive Momentum Gradient Descent)
   </font>
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#font-color-blue-size-5pt-multilayer-perceptron-instructional-videos-font">
   <font color="blue" size="5pt">
    Multilayer Perceptron Instructional Videos
   </font>
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#font-color-blue-size-5pt-test-your-understanding-font">
   <font color="blue" size="5pt">
    Test Your Understanding
   </font>
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#font-color-blue-size-6pt-code-applications-font">
   <font color="blue" size="6pt">
    Code Applications
   </font>
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#references">
     References:
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#setup">
   Setup
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#example-of-a-neural-net-in-pytorch-for-classification">
   Example of a Neural Net in PyTorch for Classification
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#example-of-classification-w-class-imbalance">
   Example of Classification w/ Class Imbalance
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section id="an-introduction-to-the-multilayer-perceptron-font">
<h1>An Introduction to the Multilayer Perceptron </font><a class="headerlink" href="#an-introduction-to-the-multilayer-perceptron-font" title="Permalink to this headline">#</a></h1>
<section id="font-color-blue-size-5pt-introduction-font">
<h2><font color='blue' size=5pt> Introduction </font><a class="headerlink" href="#font-color-blue-size-5pt-introduction-font" title="Permalink to this headline">#</a></h2>
<p>The related research started in late 1950s (<a class="reference external" href="https://news.cornell.edu/stories/2019/09/professors-perceptron-paved-way-ai-60-years-too-soon">F. Rosenblatt</a>) with the “Mark I Perceptron”: the goal was to automatically detect capital letters.</p>
<table><tr>
<td>
    <img src="https://i.imgur.com/Fo4Mu7V.png" alt="Image 1"
    width='900px'> </td>
   <td>  
   <img src="https://i.imgur.com/tL8bXYl.png" alt="Image 2" width='500px'> </td>
</tr></table>
<p>Image source: <a class="reference external" href="https://jennysmoore.wordpress.com/2014/03/31/march-31-network-society-readings/">https://jennysmoore.wordpress.com/2014/03/31/march-31-network-society-readings/</a></p>
</section>
<section id="font-color-blue-size-5pt-the-artificial-neuron-font">
<h2><font color='blue' size=5pt> The Artificial Neuron </font><a class="headerlink" href="#font-color-blue-size-5pt-the-artificial-neuron-font" title="Permalink to this headline">#</a></h2>
<table><tr>
<td>
    <img src="https://i.imgur.com/JKHqlVt.png" alt="Image 1"
    width='600px'> </td>
   <td>  
   <img src="https://i.imgur.com/EtLULhh.png" alt="Image 2" width='770px'> </td>
</tr></table>
<p>Example of a neural network with five neurons:</p>
<table><tr>
<td>
    <img src="https://i.imgur.com/NQLc0B4.png" alt="Image 1"
    width='600px'> </td>
   <td>  
   <img src="https://i.imgur.com/XipowyJ.png" alt="Image 2" width='640px'> </td>
</tr></table>
<p>It is a nature-inspired design. Check out the <a class="reference external" href="https://playground.tensorflow.org/#activation=tanh&amp;batchSize=10&amp;dataset=circle%C2%AEDataset=reg-plane&amp;learningRate=0.03%C2%AEularizationRate=0&amp;noise=0&amp;networkShape=4,2&amp;seed=0.61321&amp;showTestData=false&amp;discretize=false&amp;percTrainData=50&amp;x=true&amp;y=true&amp;xTimesY=false&amp;xSquared=false&amp;ySquared=false&amp;cosX=false&amp;sinX=false&amp;cosY=false&amp;sinY=false&amp;collectStats=false&amp;problem=classification&amp;initZero=false&amp;hideText=false">playground</a>.</p>
<p><strong>Fact:</strong> A frog has enough neurons to learn how to drive your car, but if it did, it would occupy its entire memory and it would not know how to feed itself.</p>
<table><tr>
<td>
    <img src="https://i.imgur.com/so9Z0VY.png" alt="Image 1"
    width='400px'> </td>
   <td>  
   <img src="https://i.imgur.com/N6Rc9n2.png" alt="Image 2" width='250px'> </td>
</tr></table>
</section>
<section id="font-color-blue-size-5pt-brief-history-of-development-font">
<h2><font color='blue' size=5pt> Brief History of Development </font><a class="headerlink" href="#font-color-blue-size-5pt-brief-history-of-development-font" title="Permalink to this headline">#</a></h2>
<p>Neural Networks have been a success for computer vision, image analysis and classification problems; however we can use the method for regression, as well.</p>
<ul class="simple">
<li><p>It was able to identify capital letters.</p></li>
<li><p>From 1960 - 1986, things progressed relatively slowly.</p></li>
<li><p>D. Rumelhart, <a class="reference external" href="https://torontolife.com/tech/ai-superstars-google-facebook-apple-studied-guy/">G. Hinton</a> and R. Williams were able to achieve the first back-propagation network (Seminal paper “Learning Representations by back-propagating errors” Nature Vol. 323, 1986 ).</p></li>
<li><p>1990, P. Werbos, “Backpropagation Through Time: What It Does and How to Do It”</p></li>
<li><p>G. Hinton and R. Salakhutdinov examined the capability of neural nets for image recognition in 2006. Explosive research into neural nets from 2006 - today.</p></li>
</ul>
</section>
<section id="font-color-blue-size-5pt-activation-functions-font">
<h2><font color='blue' size=5pt> Activation Functions </font><a class="headerlink" href="#font-color-blue-size-5pt-activation-functions-font" title="Permalink to this headline">#</a></h2>
<p>Examples of activation functions:</p>
<style>
img {width: 10%;}
table th:first-of-type {
    width: 10%;
}
table th:nth-of-type(2) {
    width: 10%;
}
table th:nth-of-type(3) {
    width: 40%;
}
table th:nth-of-type(4) {
    width: 40%;
}
</style>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p>Name</p></th>
<th class="head"><p>Plot</p></th>
<th class="head"><p>Equation</p></th>
<th class="head"><p>Derivative</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Identity</p></td>
<td><p><img alt="Identity" src="https://i.imgur.com/OZZutkF.png" /></p></td>
<td><p>$<span class="math notranslate nohighlight">\( f(x) = x \)</span>$</p></td>
<td><p>$<span class="math notranslate nohighlight">\( f'(x) = 1 \)</span>$</p></td>
</tr>
<tr class="row-odd"><td><p>Binary step</p></td>
<td><p><img alt="Binary step" src="https://i.imgur.com/zRVpQIU.png" /></p></td>
<td><p>$<span class="math notranslate nohighlight">\( f(x) = \begin{cases} 0 &amp; \text{for } x &lt; 0 \\ 1 &amp; \text{for } x \ge 0 \end{cases} \)</span>$</p></td>
<td><p>$<span class="math notranslate nohighlight">\( f'(x) = \begin{cases} 0 &amp; \text{for } x \ne 0 \\ ? &amp; \text{for } x = 0 \end{cases} \)</span>$</p></td>
</tr>
<tr class="row-even"><td><p>Logistic (a.k.a Soft step)</p></td>
<td><p><img alt="Logistic" src="https://i.imgur.com/VtjWCF6.png" /></p></td>
<td><p>$<span class="math notranslate nohighlight">\( f(x) = \frac{1}{1 + e^{-x}} \)</span>$</p></td>
<td><p>$<span class="math notranslate nohighlight">\( f'(x) = f(x)(1 - f(x)) \)</span>$</p></td>
</tr>
<tr class="row-odd"><td><p>TanH</p></td>
<td><p><img alt="TanH" src="https://i.imgur.com/F7dSp0r.png" /></p></td>
<td><p>$<span class="math notranslate nohighlight">\( f(x) = \tanh(x) = \frac{2}{1 + e^{-2x}} - 1 \)</span>$</p></td>
<td><p>$<span class="math notranslate nohighlight">\( f'(x) = 1 - f(x)^2 \)</span>$</p></td>
</tr>
<tr class="row-even"><td><p>ArcTan</p></td>
<td><p><img alt="ArcTan" src="https://i.imgur.com/gY6mIAO.png" /></p></td>
<td><p>$<span class="math notranslate nohighlight">\( f(x) = \tan^{-1}(x) \)</span>$</p></td>
<td><p>$<span class="math notranslate nohighlight">\( f'(x) = \frac{1}{x^2 + 1} \)</span>$</p></td>
</tr>
<tr class="row-odd"><td><p>Rectified Linear Unit (ReLU)</p></td>
<td><p><img alt="ReLU" src="https://i.imgur.com/GFNymDd.png" /></p></td>
<td><p>$<span class="math notranslate nohighlight">\( f(x) = \begin{cases} 0 &amp; \text{for } x &lt; 0 \\ x &amp; \text{for } x \ge 0 \end{cases} \)</span>$</p></td>
<td><p>$<span class="math notranslate nohighlight">\( f'(x) = \begin{cases} 0 &amp; \text{for } x &lt; 0 \\ 1 &amp; \text{for } x \ge 0 \end{cases} \)</span>$</p></td>
</tr>
<tr class="row-even"><td><p>Parametric Rectified Linear Unit (PReLU)</p></td>
<td><p><img alt="PReLU" src="https://i.imgur.com/UkIefvc.png" /></p></td>
<td><p>$<span class="math notranslate nohighlight">\( f(x) = \begin{cases} \alpha x &amp; \text{for } x &lt; 0 \\ x &amp; \text{for } x \ge 0 \end{cases} \)</span>$</p></td>
<td><p>$<span class="math notranslate nohighlight">\( f'(x) = \begin{cases} \alpha &amp; \text{for } x &lt; 0 \\ 1 &amp; \text{for } x \ge 0 \end{cases} \)</span>$</p></td>
</tr>
<tr class="row-odd"><td><p>Exponential Linear Unit (ELU)</p></td>
<td><p><img alt="ELU" src="https://i.imgur.com/C5Qbkak.png" /></p></td>
<td><p>$<span class="math notranslate nohighlight">\( f(x) = \begin{cases} \alpha (e^x - 1) &amp; \text{for } x &lt; 0 \\ x &amp; \text{for } x \ge 0 \end{cases} \)</span>$</p></td>
<td><p>$<span class="math notranslate nohighlight">\( f'(x) = \begin{cases} f(x) + \alpha &amp; \text{for } x &lt; 0 \\ 1 &amp; \text{for } x \ge 0 \end{cases} \)</span>$</p></td>
</tr>
<tr class="row-even"><td><p>SoftPlus</p></td>
<td><p><img alt="SoftPlus" src="https://i.imgur.com/nzGthI4.png" /></p></td>
<td><p>$<span class="math notranslate nohighlight">\( f(x) = \log(1 + e^x) \)</span>$</p></td>
<td><p>$<span class="math notranslate nohighlight">\( f'(x) = \frac{1}{1 + e^{-x}} \)</span>$</p></td>
</tr>
<tr class="row-odd"><td><p>Swish</p></td>
<td><p><img alt="Swish" src="https://i.imgur.com/55GMfys.png" /></p></td>
<td><p>$<span class="math notranslate nohighlight">\(f(x) = \frac{x}{1+e^-{\beta x}}\)</span>$</p></td>
<td><p>$<span class="math notranslate nohighlight">\(f'(x)=f(x)\cdot\left[1+\beta - \beta\cdot\sigma(\beta x)\right]\)</span><span class="math notranslate nohighlight">\( where \)</span>\sigma$ is the logistic sigmoid.</p></td>
</tr>
</tbody>
</table>
</section>
<section id="font-color-blue-size-5pt-backpropagation-font">
<h2><font color='blue' size=5pt> Backpropagation </font><a class="headerlink" href="#font-color-blue-size-5pt-backpropagation-font" title="Permalink to this headline">#</a></h2>
<p>Backpropagation is the process of updating the weights in a direction that is based on the calculation of the gradient of the loss function.</p>
<table><tr>
<td>
    <img src="https://i.imgur.com/ea5kWB3.png" alt="Image 1"
    width='410px'> </td>
   <td>  
   <img src="https://i.imgur.com/ySyoqTv.png" alt="Image 2" width='620px'> </td>
</tr></table>
</section>
<section id="font-color-blue-size-5pt-gradient-descent-methods-for-optimization-font">
<h2><font color='blue' size=5pt> Gradient Descent Methods for Optimization </font><a class="headerlink" href="#font-color-blue-size-5pt-gradient-descent-methods-for-optimization-font" title="Permalink to this headline">#</a></h2>
<p>All the current optimization algorithms are based on a variant of gradient descent.</p>
<p>Let’s denote the vector of weights at step <span class="math notranslate nohighlight">\(t\)</span> by <span class="math notranslate nohighlight">\(w_t\)</span> and the gradient of the objective function with respect to the weights by <span class="math notranslate nohighlight">\(g_t\)</span>. The idea is that the gradient descent algorithm updates the weights under the following principle:</p>
<div class="math notranslate nohighlight">
\[\large w_t = w_{t-1} - \eta\cdot g_{t,t-1}\]</div>
<p>When the objective function (whose gradient with respect to the weights) is represented by <span class="math notranslate nohighlight">\(g_t\)</span> and has multiple local minima, or it has a very shallow region containing the minima, the plain gradient descent algorithm may not converge to the position sought for. To remediate this deficiency research proposed alternatives by varying the way we evaluate the learning rate each step or how we compute the “velocity” for updating the weights:</p>
<p><font color='green'>$<span class="math notranslate nohighlight">\(\Large w_t = w_{t-1} - \eta_t\cdot v_t\)</span>$ </font></p>
<p>In the equation above, <span class="math notranslate nohighlight">\(\eta_t\)</span> is an adaptive learning rate and <span class="math notranslate nohighlight">\(v_t\)</span> a modified gradient.</p>
</section>
<section id="font-color-blue-size-5pt-dynamic-learning-rates-font">
<h2><font color='blue' size=5pt> Dynamic Learning Rates </font><a class="headerlink" href="#font-color-blue-size-5pt-dynamic-learning-rates-font" title="Permalink to this headline">#</a></h2>
<p>We can consider an exponential decay, such as</p>
<div class="math notranslate nohighlight">
\[\large \eta_t = \eta_0 e^{-\lambda\cdot t}\]</div>
<p>or a polynomial decay</p>
<div class="math notranslate nohighlight">
\[\large \eta_t = \eta_0 (\beta t+1)^{-\alpha}\]</div>
</section>
<section id="font-color-blue-size-5pt-momentum-gradient-descent-font">
<h2><font color='blue' size=5pt> Momentum Gradient Descent </font><a class="headerlink" href="#font-color-blue-size-5pt-momentum-gradient-descent-font" title="Permalink to this headline">#</a></h2>
<div class="math notranslate nohighlight">
\[\large g_{t,t-1} = \partial_w \frac{1}{|\text{B}_t|}\sum_{i\in \text{B}_t}f(x_i,w_{t-1})=\frac{1}{|\text{B}_t|}\sum_{i\in \text{B}_t}h_{i,t-1}\]</div>
<p>where</p>
<div class="math notranslate nohighlight">
\[\large v_t = \beta v_{t-1} + g_{t,t-1}\]</div>
<p>and <span class="math notranslate nohighlight">\(\beta\in (0,1).\)</span></p>
<p>For an explicit formula, we have</p>
<div class="math notranslate nohighlight">
\[\large v_t = \sum_{\tau=0}^{t-1} \beta^{\tau}g_{t-\tau,t-\tau-1}\]</div>
<p>and</p>
<div class="math notranslate nohighlight">
\[\large w_t = w_{t-1} - \alpha v_t\]</div>
<p>where</p>
<div class="math notranslate nohighlight">
\[\large \alpha = \frac{\eta}{1-\beta}\]</div>
</section>
<section id="font-color-blue-size-5pt-adagrad-adaptive-gradient-descent-font">
<h2><font color='blue' size=5pt> AdaGrad (Adaptive Gradient Descent) </font><a class="headerlink" href="#font-color-blue-size-5pt-adagrad-adaptive-gradient-descent-font" title="Permalink to this headline">#</a></h2>
<div class="math notranslate nohighlight">
\[\large s_t = s_{t-1} + g_{t}^2\]</div>
<p>and</p>
<div class="math notranslate nohighlight">
\[\large w_t= w_{t-1} - \frac{\eta}{\sqrt{s_t+\epsilon}}\cdot g_t\]</div>
</section>
<section id="font-color-blue-size-5pt-rmsprop-root-mean-square-propagation-font">
<h2><font color='blue' size=5pt> RMSProp (Root Mean Square Propagation) </font><a class="headerlink" href="#font-color-blue-size-5pt-rmsprop-root-mean-square-propagation-font" title="Permalink to this headline">#</a></h2>
<div class="math notranslate nohighlight">
\[\large s_t = \gamma\cdot s_{t-1} + (1-\gamma)\cdot g_{t}^2\]</div>
<p>and</p>
<div class="math notranslate nohighlight">
\[\large w_t= w_{t-1} - \frac{\eta}{\sqrt{s_t+\epsilon}}\cdot g_t\]</div>
<p>Thus, we have</p>
<div class="math notranslate nohighlight">
\[\large s_t = (1-\gamma)\cdot (g_t^2+\gamma g_{t-1}^2+\gamma^2 g_{t-2} +\gamma^3 g_{t-2} + ... + \gamma^{\tau} g_0)\]</div>
</section>
<section id="font-color-blue-size-5pt-adam-adaptive-momentum-gradient-descent-font">
<h2><font color='blue' size=5pt> ADAM (Adaptive Momentum Gradient Descent) </font><a class="headerlink" href="#font-color-blue-size-5pt-adam-adaptive-momentum-gradient-descent-font" title="Permalink to this headline">#</a></h2>
<div class="math notranslate nohighlight">
\[\large v_t = \beta_1  v_{t-1} +(1-\beta_1) g_t\]</div>
<p>and</p>
<div class="math notranslate nohighlight">
\[\large s_t = \beta_2 s_{t-1} + (1-\beta_2) g_t^2 \]</div>
<p>We further consider</p>
<div class="math notranslate nohighlight">
\[\large \hat{v}_t = \frac{v_t}{1-\beta_1}, \text{and  } \hat{s}_t = \frac{s_t}{1-\beta_2} \]</div>
<p>and</p>
<div class="math notranslate nohighlight">
\[\large \hat{g}_{t} = \frac{\eta\cdot \hat{v}_t}{\sqrt{\hat{s}_t}+\epsilon}\]</div>
<p>The updates to the weights are implemented as follows</p>
<div class="math notranslate nohighlight">
\[\large w_t = w_{t-1} - \hat{g}_t\]</div>
</section>
<section id="font-color-blue-size-5pt-multilayer-perceptron-instructional-videos-font">
<h2><font color='blue' size=5pt> Multilayer Perceptron Instructional Videos </font><a class="headerlink" href="#font-color-blue-size-5pt-multilayer-perceptron-instructional-videos-font" title="Permalink to this headline">#</a></h2>
<p>The first 2 are required. The last 2 are optional but highly recommended, even if you have not had any calculus or linear algebra!</p>
<ol class="simple">
<li><p><a class="reference external" href="https://www.youtube.com/watch?v=aircAruvnKk">But what is a Neural Network?</a></p></li>
<li><p><a class="reference external" href="https://www.youtube.com/watch?v=IHZwWFHWa-w">Gradient descent, how neural networks learn</a></p></li>
<li><p><a class="reference external" href="https://www.youtube.com/watch?v=Ilg3gGewQ5U">What is backpropagation really doing?</a></p></li>
<li><p><a class="reference external" href="https://www.youtube.com/watch?v=tIeHLnjs5U8">Backpropagation calculus</a></p></li>
</ol>
</section>
<section id="font-color-blue-size-5pt-test-your-understanding-font">
<h2><font color='blue' size=5pt> Test Your Understanding </font><a class="headerlink" href="#font-color-blue-size-5pt-test-your-understanding-font" title="Permalink to this headline">#</a></h2>
<ol class="simple">
<li><p>What is a multilayer perceptron?</p></li>
<li><p>What is a hidden layer?</p></li>
<li><p>The network in the video was on the small-ish side, having only 2 hidden layers with 16 neurons each.  How many total parameters (i.e. weights and biases) have to be determined during the training process for this network?</p></li>
<li><p>Without reference to the calculus involved, do you understand the concept of gradient descent?</p></li>
</ol>
</section>
<section id="font-color-blue-size-6pt-code-applications-font">
<h2><font color='blue' size=6pt> Code Applications </font><a class="headerlink" href="#font-color-blue-size-6pt-code-applications-font" title="Permalink to this headline">#</a></h2>
<hr class="docutils" />
<section id="references">
<h3>References:<a class="headerlink" href="#references" title="Permalink to this headline">#</a></h3>
<ol class="simple">
<li><p><a class="reference external" href="https://www.amazon.com/Programming-PyTorch-Deep-Learning-Applications/dp/1492045357?asc_campaign=343db101986d123592617b298c3e663c&amp;asc_source=01HPSC557H8MR8GX011W62TB1D&amp;tag=snx192-20">Programming PyTorch for Deep Learning</a></p></li>
<li><p><a class="reference external" href="https://github.com/curiousily/Getting-Things-Done-with-Pytorch">Getting Things Done with PyTorch</a></p></li>
</ol>
</section>
</section>
<section id="setup">
<h2>Setup<a class="headerlink" href="#setup" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="k">if</span> <span class="s1">&#39;google.colab&#39;</span> <span class="ow">in</span> <span class="nb">str</span><span class="p">(</span><span class="n">get_ipython</span><span class="p">()):</span>
  <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Running on CoLab&#39;</span><span class="p">)</span>
  <span class="kn">from</span> <span class="nn">google.colab</span> <span class="kn">import</span> <span class="n">drive</span>
  <span class="n">drive</span><span class="o">.</span><span class="n">mount</span><span class="p">(</span><span class="s1">&#39;/content/drive&#39;</span><span class="p">)</span>
  <span class="n">os</span><span class="o">.</span><span class="n">chdir</span><span class="p">(</span><span class="s1">&#39;/content/drive/My Drive/Data Sets&#39;</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
  <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Running locally&#39;</span><span class="p">)</span>
  <span class="n">os</span><span class="o">.</span><span class="n">chdir</span><span class="p">(</span><span class="s1">&#39;../Data&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Running on CoLab
Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(&quot;/content/drive&quot;, force_remount=True).
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>


<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">TensorDataset</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_wine</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="example-of-a-neural-net-in-pytorch-for-classification">
<h2>Example of a Neural Net in PyTorch for Classification<a class="headerlink" href="#example-of-a-neural-net-in-pytorch-for-classification" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Load and preprocess the data</span>
<span class="n">wine_data</span> <span class="o">=</span> <span class="n">load_wine</span><span class="p">()</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">wine_data</span><span class="o">.</span><span class="n">data</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">wine_data</span><span class="o">.</span><span class="n">target</span>

<span class="c1"># Standardize the features</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="c1"># Split the dataset into training and test sets</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># Convert the data to PyTorch tensors</span>
<span class="n">X_train_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
<span class="n">X_test_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
<span class="n">y_train_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>
<span class="n">y_test_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>

<span class="c1"># Create DataLoader for training and testing</span>
<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span><span class="n">X_train_tensor</span><span class="p">,</span> <span class="n">y_train_tensor</span><span class="p">)</span>
<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span><span class="n">X_test_tensor</span><span class="p">,</span> <span class="n">y_test_tensor</span><span class="p">)</span>
<span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">test_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># Define a simple neural network</span>
<span class="k">class</span> <span class="nc">WineNet</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">n_features</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">WineNet</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">n_features</span><span class="p">,</span> <span class="mi">50</span><span class="p">)</span><span class="o">.</span><span class="n">double</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="mi">30</span><span class="p">)</span><span class="o">.</span><span class="n">double</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">double</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>

<span class="c1"># Initialize the model, loss function, and optimizer</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">WineNet</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">)</span>

<span class="c1"># Train the model</span>
<span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">100</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">X_batch</span><span class="p">,</span> <span class="n">y_batch</span> <span class="ow">in</span> <span class="n">train_loader</span><span class="p">:</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">X_batch</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">y_batch</span><span class="p">)</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

    <span class="k">if</span> <span class="p">(</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="mi">10</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Epoch [</span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s1">/</span><span class="si">{</span><span class="n">num_epochs</span><span class="si">}</span><span class="s1">], Loss: </span><span class="si">{</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="c1"># Evaluate the model on the test set</span>
<span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">y_pred_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">y_true_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">X_batch</span><span class="p">,</span> <span class="n">y_batch</span> <span class="ow">in</span> <span class="n">test_loader</span><span class="p">:</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">X_batch</span><span class="p">)</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">y_pred</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">y_pred_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span>
        <span class="n">y_true_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y_batch</span><span class="p">)</span>

    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">y_pred_list</span><span class="p">)</span>
    <span class="n">y_true</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">y_true_list</span><span class="p">)</span>
    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_true</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">y_pred</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Accuracy on test set: </span><span class="si">{</span><span class="n">accuracy</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch [10/100], Loss: 0.5738
Epoch [20/100], Loss: 0.1444
Epoch [30/100], Loss: 0.0459
Epoch [40/100], Loss: 0.0263
Epoch [50/100], Loss: 0.0081
Epoch [60/100], Loss: 0.0122
Epoch [70/100], Loss: 0.0090
Epoch [80/100], Loss: 0.0048
Epoch [90/100], Loss: 0.0050
Epoch [100/100], Loss: 0.0043
Accuracy on test set: 0.9815
</pre></div>
</div>
</div>
</div>
</section>
<section id="example-of-classification-w-class-imbalance">
<h2>Example of Classification w/ Class Imbalance<a class="headerlink" href="#example-of-classification-w-class-imbalance" title="Permalink to this headline">#</a></h2>
<p>Reference: <a class="reference external" href="https://github.com/curiousily/Getting-Things-Done-with-Pytorch/blob/master/04.first-neural-network.ipynb">https://github.com/curiousily/Getting-Things-Done-with-Pytorch/blob/master/04.first-neural-network.ipynb</a></p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "ai4fusion-wmschool/summer2024",
            ref: "main",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="Supervised_Learning_DTrees_Random_Forest_and_XGBoost.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Supervised Learning - Decision Trees,  Random Forest and eXtreme Gradient Boosting (XGBoost) </font></p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="NFlows_BasicExample_new.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">A very basic example from the NFlows Library</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Open-Fair-Fusion for Machine Learning Applications<br/>
  
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>